import torch
import torch.nn.modules
import torch.nn
import numpy as np
from torch.autograd import Variable #torch的基本变量
import torch.nn.functional as F #里面有很多torch的函数
import matplotlib.pyplot as plt
import random

NUM_OF_TEST_SET=2000
NUM_OF_PARTY=5
PARTY_DATA=6000
NUM_OF_ALL_DATA=32561
NUM_OF_FEATURE=14
#0代表不是
#1代表是

class Net(torch.nn.Module):
    def __init__(self,NF,NH1,NH2,NO):
        super(Net,self).__init__()
        self.layer1=torch.nn.Linear(NF,NH1)
        self.layer2=torch.nn.Linear(NH1,NH2)
        self.layer3=torch.nn.Linear(NH2,NO)
    def forward(self, input):
        x=F.relu(self.layer1(input))
        x=F.relu(self.layer2(x))
        res=torch.sigmoid(self.layer3(x))
        return res

class Party:
    def __init__(self,NF,NH1,NH2,NO):
        self.Data=[]
        self.NUMOFFEATURE=0
        self.NUMOFDATA=0
        self.Net=Net(NF,NH1,NH2,NO)
        self.Y=None
    def Update(self):
        self.NUMOFDATA=len(self.Data)
        self.NUMOFFEATURE=len(self.Data[0])-1
        #print("self.NUM_OF_FEATURE is {}".format(self.NUMOFFEATURE))
        for index,item in enumerate(self.Data):
            if item[-1]==0:
                self.Data[index][-1]=-1
        self.Y=Variable(torch.from_numpy(np.array([item[-1] for item in self.Data]).reshape(self.NUMOFDATA,1)).float())#是或者不是
        self.Data=Variable(torch.from_numpy(np.array([item[:-1] for item in self.Data])).float())


    def Train(self):
        optimizer=torch.optim.SGD(self.Net.parameters(),lr=0.1)
        LossFunction=torch.nn.SoftMarginLoss()

        loss_list=[]
        prediction = self.Net(self.Data)
        loss = LossFunction(prediction, self.Y)

        last = loss.detach().numpy()
        loss_list.append(last)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        prediction = self.Net(self.Data)
        loss = LossFunction(prediction, self.Y)
        now = loss.detach().numpy()
        loss_list.append(now)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


        while last-now>1e-5:
            prediction=self.Net(self.Data)
            loss=LossFunction(prediction,self.Y)
            last=now
            now=loss.detach().numpy()
            loss_list.append(last)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        #plt.plot(x,loss_list)
        #plt.show()
        return loss_list

    def DeepNetPredict(self,feature):
        return self.Net(feature)
    def ConvertFeature(self,feature):
        res=[]
        for item in feature:
            print(item)
            if item in self.GetClass:
                res.append(self.GetClass[item])
            else:return []
        return res

class DataLoader():
    def __init__(self):
        self.RawData = []
        self.Data = []
        self.GetClass = {}
        self.SecondFeatureMin = 12285
        self.SecondFeatureMax = 1484705
        self.Second = self.SecondFeatureMax - self.SecondFeatureMin

        self.NUMOFFEATURE = 0
        self.NUMOFDATA = 0
    def LoadData(self,PATH):
        with open(PATH,'r') as f:
            for line in f:
                self.RawData.append([thing.strip() for thing in line.split(',')])
        self.RawData=self.RawData[:-1]
        self.NUMOFDATA=len(self.RawData)
        NUM_OF_FEATURE=len(self.RawData[0])-1
        #print(NUM_OF_FEATURE)

    def ShowRawData(self):
        for item in self.RawData:
            print(item)
    def WashData(self):
        attribute=len(self.RawData[0])
        #print("attribute: {}".format(attribute))

        index=0
        while index<attribute:
            #print('index: {}'.format(index))
            cnt=0
            temp=[i[index] for i in self.RawData]

            for item in temp:
                if item not in self.GetClass:
                    self.GetClass[item]=cnt
                    cnt+=1
            index+=1
        self.NUMOFFEATURE=index

        #print("feature number is {}.".format(self.NUMOFFEATURE))
        for line in self.RawData:
            t = []
            for j,f in enumerate(line):
                if j==0:
                    t.append(float(f)/10)
                elif j==2:
                    t.append(round(float(f)/self.Second,4))
                elif j==10 or j==11:
                    t.append(float(f)/2000)
                elif j==12:
                    t.append(float(f)/10)
                else:
                    t.append(self.GetClass[f]/10)
            self.Data.append(t)

        #print("data length is {}".format(len(self.Data[0])))
    def ShowData(self):
        for item in self.Data:
            print(item)
    def AssignSpecificData(self,Party,start,end):
        Party.Data=self.Data[start:end]
    def AssignRandomData(self,Party,howmany):
        cnt=1
        while cnt<howmany:
            index=random.randint(0,self.NUMOFDATA-1)
            Party.Data.append(self.Data[index])
            cnt+=1

class Tester:
    def __init__(self):
        self.Data = []

        self.NUMOFFEATURE = 0
        self.NUMOFDATA = 0
    def Update(self):
        self.NUMOFDATA=len(self.Data)
        self.NUMOFFEATURE=len(self.Data[0])-1
        #print("self.NUM_OF_FEATURE is {}".format(self.NUMOFFEATURE))
        for index,item in enumerate(self.Data):
            if item[-1]==0:
                self.Data[index][-1]=-1
        self.Y=Variable(torch.from_numpy(np.array([item[-1] for item in self.Data]).reshape(self.NUMOFDATA,1)).float())#是或者不是
        self.Data=Variable(torch.from_numpy(np.array([item[:-1] for item in self.Data])).float())

    def Test(self,A):
        LossFunction = torch.nn.SoftMarginLoss()
        prediction = A.Net(self.Data)
        loss=LossFunction(prediction,self.Y)
        return loss.detach().numpy()

def OneGuyManyTime(who,time):
    loss = []
    loss.clear()
    for i in range(time):
        loss.append(who.Train())
    plt.figure()
    plt.title('{} times in one party'.format(time))
    for i in range(time):
        plt.subplot(2, 3, i + 1)
        plt.plot([num for num in range(len(loss[i]))], loss[i])
        plt.ylim(0,1)

    plt.show()

def FiveGuysOneTime(who):
    loss=[]
    plt.figure()
    plt.title("Five Guys One Time")
    for i,p in enumerate(who):
        loss.append(p.Train())
        plt.subplot(2,3,i+1)
        plt.plot([num for num in range(len(loss[i]))],loss[i])
#        plt.ylim(0.6,0.8)
    plt.show()
def ShowError(who,tester):
    error=[]
    plt.figure()
    plt.title("error of everybody")
    for p in who:
        error.append(tester.Test(p))

    plt.bar([i+1 for i in range(len(error))],error)
    plt.ylim(0.694,0.697)
    plt.show()
    return error


if __name__=="__main__":
    FilePath=r'C:\Users\Lenovo\Desktop\adult.data'

    #simulation of federated learning
    #loader进行装载、清洗数据
    loader=DataLoader()
    loader.LoadData(FilePath)
    loader.WashData()
    #loader.ShowData()

    #assign data to 5 parties.

    p=[]
    for i in range(5):
        temp=Party(14,10,9,1)
        loader.AssignRandomData(temp,2000)
        temp.Update()

        p.append(temp)

    #assign data to global aggregator
    Global=Party(14,10,9,1)
    loader.AssignRandomData(Global,10000)
    Global.Update()
    p.append(Global)

    #train once in all parties including global one.
    FiveGuysOneTime(p)

    #test error status.
    tester=Tester()
    loader.AssignSpecificData(tester,31000,32000)
    tester.Update()

    ShowError(p,tester)


    exit(0)


    #1.数据选取
    #2.特征表示
    #3.训练网络（规模、参数）
    #4.test写错


